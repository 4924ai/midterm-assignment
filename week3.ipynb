{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Code Snippet 3-3 helper Functions for Backpropagation"
      ],
      "metadata": {
        "id": "UG2zV8a53QL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_learning():\n",
        "  print('Current weights:')\n",
        "  for i, w in enumerate(n_w):\n",
        "    print('neuron',i, ':w0=', '%5.2f'%w[0],\n",
        "          ',w1=', '%5.2f'%w[1], ',w2=',\n",
        "          '%5.2f'%w[2])\n",
        "    print('-----')\n",
        "    def forward_pass(x):\n",
        "      global n_y\n",
        "      n_y[0]=np.tanh(np.dot(n_w[0],x)) #Neuron 0\n",
        "      n_y[1] = np.tanh(np.dot(n_w[1],x)) #Neuron 1\n",
        "      n2_inputs = np.array([1.0, n_y[0], n_y[1]])#1.0 is bias\n",
        "      z2 = np.dot(n_w[2], n2_inputs)\n",
        "      n_y[2] = 1.0/(1.0 + np.exp(-z2))\n",
        "      "
      ],
      "metadata": {
        "id": "iSG7L9G6nZn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(y_truth): global n_error\n",
        "error_prime = -(y_truth - n_y[2]) #Derivative of loss-func\n",
        "derivative = n_y[2]*(1.0 - n_y[2]) #Logistic derivative\n",
        "n_error[2] = error_prime * derivative\n",
        "derivative = 1.0 - n_y[0]**2#tanh derivative\n",
        "n_error[0] = n_w[2][1]*n_error[2] *derivative\n",
        "derivative = 1.0 - n_y[1]**2 #Tanh derivative\n",
        "n_error[1] = n_w[2][2]*n_error[2] * derivative\n",
        "\n",
        "def adjust_weights(x):\n",
        "\n",
        "  global n_w\n",
        "  n_w[0]-= (x * LEARNING_RATE * n_error[0])\n",
        "  n_w[1]-= (x * LEARNING_RATE * n_error[1])\n",
        "  n2_inputs=np.array([1.0,n_y[0],n_y[1]])#1.0 is bias\n",
        "  n_w[2]-=(n2_inputs * LEARNING_RATE * n_error[2])\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "gbomedNa3fzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}